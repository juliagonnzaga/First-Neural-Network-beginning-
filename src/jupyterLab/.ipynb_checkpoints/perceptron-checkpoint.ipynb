{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Perceptron from Scratch \n",
    "\n",
    "The Perceptron is the predecessor of the Multilayer Perceptron (MLP) Artificial Neural Networks. It is a well known, bio-inspired algorithm to do supervised learning. It works as a linear classifier, as we can see in the image:\n",
    "\n",
    "![A simple Perceptron graphic description](\"jupyterLab/imgs/perceptron.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the code we did on the workshop. It might be a computational version of the neuron represented by this image. \n",
    "First of all, we need to import the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "\n",
    "    def __init__(self, n_input, alpha=0.01):\n",
    "        self.bias_weight = random.uniform(-1, 1)\n",
    "        self.alpha = alpha\n",
    "        self.weights = []\n",
    "        for i in range(n_input):\n",
    "            self.weights.append(random.uniform(-1, 1))\n",
    "        \n",
    "    def classify(self, input):\n",
    "        summation = 0\n",
    "        summation += self.bias_weight * 1\n",
    "        for i in range(len(self.weights)):\n",
    "            summation += self.weights[i] * input[i]\n",
    "        return self.activation(summation)\n",
    "\n",
    "    def activation(self, value):\n",
    "        if(value < 0):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def train(self, input, target):\n",
    "        guess = self.classify(input)\n",
    "        error = target - guess\n",
    "        self.bias_weight += 1 * error * self.alpha\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += input[i] * error * self.alpha\n",
    "        return error\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create and test this neuron, althought it basicaly was created at random and the best we can expect from it is a random classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(1)\n",
    "perceptron.classify([10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the same perceptron will always give us the same answer, unless we train it again (and, therefore, update its **weights**). The following cells can show it easily:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always the same values for the same perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    print(perceptron.classify([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we create new perceptrons (remember that those perceptrons have their wheights initialized randomly). We **may** have different classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    newPerceptron = Perceptron(1)\n",
    "    print(newPerceptron.classify([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try training our neuron. Notice that it have just one input and one output, so our classifier would be able to work in just one dimension. Let's say we want a classifier to tell us if a number is less than 50. We should start by creating a proper database, in our case we are using two lists to keep the database: \n",
    "\n",
    "- `X` : a list of lists representing the parameters ou features\n",
    "- `y` : a list with the expected outputs\n",
    "\n",
    "For our \"less than 50\" classifier, we need something like this:\n",
    "\n",
    "| `X` | `y` |\n",
    "|-----|-----|\n",
    "| 10  |  1  |\n",
    "| 30  |  1  |\n",
    "| 55  |  0  |\n",
    "| 100 |  0  |\n",
    "| 20  |  1  |\n",
    "\n",
    "Yes, we could create those two lists by hand. But since we already know the function behind those values, we might want to avoid this trouble and just populate it using a foor loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(80):\n",
    "    x = random.randrange(0,100)\n",
    "    X.append([x])\n",
    "    if x < 50:\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train our neuron over a few interations with this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(100):\n",
    "    for i in range(len(X)):\n",
    "        perceptron.train(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check if our neuron learned to classify if a number is less than 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    x = random.randrange(0,100)\n",
    "    print(x,\" is less than 50? \", perceptron.classify([x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even after 100 interations we may not have a exact classifier. In this case, it is might happen due to our limited dataset. We have a dataset with 80 examples and probably we are not covering all the possible cases. \n",
    "\n",
    "> #### **Remember: Your classifier is as good as the data you fed it.\n",
    "\n",
    "Let's take a deep look into our classifier and try to find where lies its boundary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(45,55):\n",
    "    print(x, \" is less than 50? \", perceptron.classify([x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actually, do we really need the 100 iterations to train this neuron?\n",
    "Let's see how our neuron is learning during the training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(1)  \n",
    "errors = []    \n",
    "\n",
    "for iteration in range(100):\n",
    "    iteration_error = 0\n",
    "    for i in range(len(X)):\n",
    "        current_error = perceptron.train(X[i], y[i])\n",
    "        iteration_error = iteration_error + current_error\n",
    "    errors.append(iteration_error/len(X))\n",
    "    \n",
    "for i in range(len(errors)):\n",
    "    plt.plot(i, errors[i], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hum, so we did a lot of unnecessary training. How we could optimize it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron(1)  \n",
    "errors = []    \n",
    "\n",
    "iteration_errors = 1\n",
    "while(iteration_errors!=0):\n",
    "    iteration_errors = 0\n",
    "    for i in range(len(X)):\n",
    "        current_error = perceptron.train(X[i], y[i])\n",
    "        iteration_errors = iteration_errors + current_error\n",
    "    errors.append(iteration_errors/len(X))\n",
    "    \n",
    "for i in range(len(errors)):\n",
    "    plt.plot(i, errors[i], 'ro')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
