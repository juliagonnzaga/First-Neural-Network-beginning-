{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a Perceptron from Scratch \n",
    "\n",
    "The Perceptron is the predecessor of the Multilayer Perceptron (MLP) Artificial Neural Networks. It is a well known, bio-inspired algorithm to do supervised learning. It works as a linear classifier, as we can see in the image:\n",
    "\n",
    "![A simple Perceptron graphic description](\"jupyterLab/imgs/perceptron.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try the code we did on the workshop. It might be a computational version of the neuron represented by this image. \n",
    "First of all, we need to import the packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron():\n",
    "\n",
    "    def __init__(self, n_input, alpha=0.01):\n",
    "        self.bias_weight = random.uniform(-1, 1)\n",
    "        self.alpha = alpha\n",
    "        self.weights = []\n",
    "        for i in range(n_input):\n",
    "            self.weights.append(random.uniform(-1, 1))\n",
    "        \n",
    "    def classify(self, input):\n",
    "        summation = 0\n",
    "        summation += self.bias_weight * 1\n",
    "        for i in range(len(self.weights)):\n",
    "            summation += self.weights[i] * input[i]\n",
    "        return self.activation(summation)\n",
    "\n",
    "    def activation(self, value):\n",
    "        if(value < 0):\n",
    "            return 0\n",
    "        else:\n",
    "            return 1\n",
    "\n",
    "    def train(self, input, target):\n",
    "        guess = self.classify(input)\n",
    "        error = target - guess\n",
    "        self.bias_weight += 1 * error * self.alpha\n",
    "        for i in range(len(self.weights)):\n",
    "            self.weights[i] += input[i] * error * self.alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create and test this neuron, althought it basicaly was created at random and the best we can expect from it is a random classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perceptron = Perceptron(1)\n",
    "perceptron.classify([10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the same perceptron will always give us the same answer, unless we train it again (and, therefore, update its **weights**). The following cells can show it easily:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Always the same values for the same perceptron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(perceptron.classify([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But if we create new perceptrons (remember that those perceptrons have their wheights initialized randomly). We **may** have different classifiers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "1\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    newPerceptron = Perceptron(1)\n",
    "    print(newPerceptron.classify([10]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's try training our neuron. Notice that it have just one input and one output, so our classifier would be able to work in just one dimension. Let's say we want a classifier to tell us if a number is less than 50. We should start by creating a proper database, in our case we are using two lists to keep the database: \n",
    "\n",
    "- `X` : a list of lists representing the parameters ou features\n",
    "- `y` : a list with the expected outputs\n",
    "\n",
    "For our \"less than 50\" classifier, we need something like this:\n",
    "\n",
    "| `X` | `y` |\n",
    "|-----|-----|\n",
    "| 10  |  1  |\n",
    "| 30  |  1  |\n",
    "| 55  |  0  |\n",
    "| 100 |  0  |\n",
    "| 20  |  1  |\n",
    "\n",
    "Yes, we could create those two lists by hand. But since we already know the function behind those values, we might want to avoid this trouble and just populate it using a foor loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "y = []\n",
    "\n",
    "for i in range(80):\n",
    "    x = random.randrange(0,100)\n",
    "    X.append([x])\n",
    "    if x < 50:\n",
    "        y.append(1)\n",
    "    else:\n",
    "        y.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train our neuron over a few interations with this dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iteration in range(100):\n",
    "    for i in range(len(X)):\n",
    "        perceptron.train(X[i], y[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check if our neuron learned to classify if a number is less than 50:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18  is less than 50?  1\n",
      "68  is less than 50?  0\n",
      "97  is less than 50?  0\n",
      "76  is less than 50?  0\n",
      "22  is less than 50?  1\n",
      "50  is less than 50?  0\n",
      "95  is less than 50?  0\n",
      "88  is less than 50?  0\n",
      "32  is less than 50?  1\n",
      "4  is less than 50?  1\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    x = random.randrange(0,100)\n",
    "    print(x,\" is less than 50? \", perceptron.classify([x]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that even after 100 interations we may not have a exact classifier. In this case, it is might happen due to our limited dataset. We have a dataset with 80 examples and probably we are not covering all the possible cases. \n",
    "\n",
    "> #### **Remember: Your classifier is as good as the data you fed it.\n",
    "\n",
    "Let's take a deep look into our classifier and try to find where lies its boundary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45  is less than 50?  1\n",
      "46  is less than 50?  1\n",
      "47  is less than 50?  1\n",
      "48  is less than 50?  1\n",
      "49  is less than 50?  1\n",
      "50  is less than 50?  0\n",
      "51  is less than 50?  0\n",
      "52  is less than 50?  0\n",
      "53  is less than 50?  0\n",
      "54  is less than 50?  0\n"
     ]
    }
   ],
   "source": [
    "for x in range(45,55):\n",
    "    print(x, \" is less than 50? \", perceptron.classify([x]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
